{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Assignment  week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: \n",
    "\n",
    "__Student id(s)__ : \n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n",
    "\n",
    "### Standard option\n",
    "Create a search engine for one of the collections listed below:\n",
    "\n",
    "\n",
    "#### Examples of collections\n",
    "\n",
    "* Wikipedia: dumps are available at <https://dumps.wikimedia.org/nlwiki/latest/> You should get the file <https://dumps.wikimedia.org/nlwiki/latest/nlwiki-latest-pages-articles.xml.bz2> (everything) or a smaller part to start with, e.g., <https://dumps.wikimedia.org/nlwiki/latest/nlwiki-latest-pages-articles1.xml.bz2>\n",
    "* Enron email dataset: see e.g. <https://www.cs.cmu.edu/~./enron/>\n",
    "* 400K questions and 1.4M answers from goeievraag.nl: <http://maartenmarx.nl/teaching/zoekmachines/Data/goeievraag.zip>\n",
    "* the _kamervragen_ collection also used before: <http://maartenmarx.nl/teaching/zoekmachines/Data/kvr.zip> (you know this dataset well, so make your assignment extra exciting)\n",
    "* ~~[Hillary Clinton Email collection](https://archive.org/details/hillary-clinton-emails-august-31-release) See also our <http://maartenmarx.nl/teaching/zoekmachines/Data/> folder.~~\n",
    "* [part of ArchivX](http://www.cs.cornell.edu/projects/kddcup/datasets.html) Scientific articles in latex, with lots of metadata\n",
    "* the <a href=\"http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html\">Reuters newspaper collection</a>  \n",
    "\n",
    "             \n",
    "            \n",
    "Here is an example of a (small) document from Reuters:            \n",
    "\n",
    "```\n",
    "<REUTERS TOPICS=\"NO\" LEWISSPLIT=\"TRAIN\" CGISPLIT=\"TRAINING-SET\" OLDID=\"5546\" NEWID=\"3\">\n",
    "<DATE>26-FEB-1987 15:03:27.51</DATE>\n",
    "<TOPICS></TOPICS>\n",
    "<PLACES><D>usa</D></PLACES>\n",
    "<PEOPLE></PEOPLE>\n",
    "<ORGS></ORGS>\n",
    "<EXCHANGES></EXCHANGES>\n",
    "<COMPANIES></COMPANIES>\n",
    "<UNKNOWN> \n",
    "&#5;&#5;&#5;F A\n",
    "&#22;&#22;&#1;f0714&#31;reute\n",
    "d f BC-TEXAS-COMMERCE-BANCSH   02-26 0064</UNKNOWN>\n",
    "<TEXT>&#2;\n",
    "<TITLE>TEXAS COMMERCE BANCSHARES &lt;TCB> FILES PLAN</TITLE>\n",
    "<DATELINE>    HOUSTON, Feb 26 - </DATELINE><BODY>Texas Commerce Bancshares Inc's Texas\n",
    "Commerce Bank-Houston said it filed an application with the\n",
    "Comptroller of the Currency in an effort to create the largest\n",
    "banking network in Harris County.\n",
    "    The bank said the network would link 31 banks having\n",
    "13.5 billion dlrs in assets and 7.5 billion dlrs in deposits.\n",
    "       \n",
    " Reuter\n",
    "&#3;</BODY></TEXT>\n",
    "</REUTERS>\n",
    "```\n",
    "   \n",
    "### Other options\n",
    "* Provided that you come up with a non trivial collection you can create a search engine using a different collection and also different software, as long as it is not done in MySQL.\n",
    "* Discuss this with the assistants.\n",
    "    * Convince us that your data set is interesting and your software solution worthwhile investigating.\n",
    "* For the presentations it is fun to see something else.\n",
    "* Usually it has a positive effect on your mark if you do something completely different ;-)\n",
    "* You should do the same requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Requirements</h2>\n",
    "        <p>Each of the following points <strong>must</strong> be addressed. Create a seperate page on the wiki for each point. Make sure these pages can be found from the menu of your wiki. \n",
    "        Explain what you did, and exemplify with links to screenshots/a working system.</p>\n",
    "        <ol>\n",
    "        <li>Search as we know it from Google. Give a result page (SERP), with links to the documents and some description of each hit.</li>\n",
    "            <li>Advanced search. Let a user be able to search in several fields, also in several fields simulteanously. Queries like \"return articles with a title  about XXX  and which are   about YYY in the period ZZZ\" should be possible.\n",
    "             </li>\n",
    "        <li>Do one of the following:\n",
    "            <ol><li>Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query.\n",
    "            You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion). </li>\n",
    "                <li>Represent each document   with a word-cloud. </li></ol>\n",
    "        <br/>You can use several techniques to get rid of high frequency, but meaningless words: of course IDF, but also mutual information (see 13.5.1), or of course the technique from the paper by Kaptein et al on wordclouds.\n",
    "        </li>\n",
    "          <!--  <li>Group (nearly) identical documents. It is bad if two or more of the precious places of your top ten hits are occupied by near identical copies of a document.\n",
    "            Even more so if it is not relevant! So, get rid of these, by grouping them for instance. You get an idea of these duplicates if you search for \"neuken\".</li>\n",
    "            -->\n",
    "            <li>Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.</li>\n",
    "            <li>Provide Faceted Search next to the traditional list of results. For the \"Reuters\" collection, use the Category information as facet values.</li>\n",
    "            <li><strong>Evaluate your results</strong> Let 2 persons assess the relevancy of the top 10 documents for <strong>5 different queries</strong>. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 5 queries, and the two relevance assesments. \n",
    "                Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries.  \n",
    "                Describe clearly how you solved differences in judgements.\n",
    "            <br/>\n",
    "            Create your queries in the following format:\n",
    "<pre>\n",
    "&lt;topic number=\"6\"  >\n",
    "    &lt;query>kcs&lt;/query>\n",
    "    &lt;description>Find information on the Kansas City Southern railroad.\n",
    "    &lt;/description>\n",
    "\n",
    "&lt;/topic>\n",
    "\n",
    "&lt;topic number=\"16\"  >\n",
    "    &lt;query>arizona game and fish&lt;/query>\n",
    "    &lt;description>I'm looking for information about fishing and hunting\n",
    "    in Arizona.\n",
    "    &lt;/description>\n",
    "&lt;/topic>\n",
    "</pre>\n",
    "    So, both provide the actual query, and a description of the information need that was behind the query.\n",
    "    <br/>\n",
    "    Give a small set of clear guidelines for judging the results, and let your judges follow these guidelines.\n",
    "    <br/>\n",
    "    It is far more interesting to have difficult queries (both for the search engine and for the judges) than to have queries on which all ten retrieved documents are relevant.\n",
    "    So, try to create a good list of information needs.\n",
    "\n",
    "</li>\n",
    "<li>Change the ranking of your system, compute the average precision at 10 using your 5 queries, compare the results to your old system, and EXPLAIN what is going on.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Presentation</h2>\n",
    "<p>During your presentation you should have a live working search engine, that you demonstrate on the spot. Your presentation should be structured so that you will show all  requirements.\n",
    "You will be asked to show how your system works using information needs coming  from the audience.</p>\n",
    "<p>**Hint:** focus on a special aspect of your project. Everyone has done something similar, so your audience knows what was hard and what was terrible. Pick something you think will interest them.</p>\n",
    "\n",
    "\n",
    "<h2>How you will be marked</h2>\n",
    "<ul>\n",
    "    <li>Sent the URL of your guthub wiki to Maarten Marx BEFORE the presentation.</li>\n",
    "    <li>The first page of the wiki should contain:\n",
    "        <ol>\n",
    "            <li>The names and student numbers of the project members</li>\n",
    "            <li>A link to the slides of your presentation</li>\n",
    "            <li>A table of contents, with links to pages on the wiki adressing one of each of the \"must-have\" points listed above.\n",
    "            <br/>During grading, you will receive points for each of the points. So make it crystal clear where they are adressed in your wiki. Use one page per point.</li>\n",
    "\n",
    "\n",
    "</ol>\n",
    "</li>\n",
    "<li>The page for each point should contain, all rather briefly,\n",
    "<ol>\n",
    "<li>What you did and why you choose to do it in your special way.</li>\n",
    "<li>Examples of what works, and what does not work (very well).</li>\n",
    "<li>An evaluation of the quality of your work in 3-4 sentences.</li>\n",
    "</ol></li>\n",
    "<li>Clickable links to a live working demo are <strong>highly appreciated</strong>. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
